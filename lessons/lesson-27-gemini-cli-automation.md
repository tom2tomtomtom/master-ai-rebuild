# Lesson 27: Gemini CLI & Advanced Automation - Integrate AI into Workflows & Processes

*Embed Gemini AI directly into development workflows, CI/CD pipelines, and business processes without manual context switching*

---

## ðŸ’° The Business Reality

Most organizations use AI as a separate tool: open web interface, paste data, get result, apply manually. This context-switching friction costs serious time and money.

**The Alternative**: Integrate AI directly into workflows. Developers run `gemini "analyze this code"` from terminal. Emails trigger automatic categorization and response generation. Data pipelines auto-summarize findings. Tests auto-generate from code changes. No context switching. No manual copy-paste. Just AI-enhanced workflows running 24/7.

### The Cost of Context Switching

**Current State** (AI as separate tool):
- Developer writes code â†’ Opens Gemini web interface â†’ Copies code â†’ Pastes to Gemini â†’ Waits for response â†’ Copies analysis â†’ Applies to code
- Time per interaction: 3-5 minutes
- Daily interactions: 10-15
- Daily time waste: 30-75 minutes = ~6 hours/week per developer

**With Automation** (AI in workflow):
- Developer writes code â†’ Type: `gemini "review this"`
- Instant analysis in terminal â†’ Apply directly
- Time per interaction: 30 seconds
- Same 10-15 daily interactions
- Daily time saved: 20-60 minutes = 4-12 hours/week per developer

### Scaling Impact

**10-person development team**:
- Current manual approach: 40-120 hours/week waste on context switching
- With Gemini CLI automation: Reclaimed entirely
- Annual value: $100K-300K just from context-switching elimination
- Plus: Higher quality code, faster delivery, fewer bugs

**Email automation example**:
- Support team processing 100+ emails daily
- Current: 8-10 minutes per email = 800-1,000 hours/month
- With Gemini automation: 1-2 minutes per email = 100-200 hours/month
- Monthly savings: 700-800 hours = $70K-100K/month

### Business Impact Metrics

- **Development velocity**: +30-40% (integrated workflow assistance)
- **Email processing**: -80% time (automated categorization, response generation)
- **Code quality**: +25-35% (consistent automated review)
- **Time-to-insight**: -70-80% (real-time analysis vs. delayed)
- **Process automation potential**: +300-500% more tasks can be automated

### Adoption Reality

- 35% of development teams currently using Gemini API/CLI automation
- 82% report measurably faster workflows
- 76% using AI in CI/CD and automated pipelines
- Average productivity improvement: 150-250% on automation-enhanced tasks
- 91% see ROI within first month

### The Strategic Advantage

Organizations embedding AI into their core processes (not as bolt-on tool, but as foundational infrastructure) achieve:
- 2-3x faster execution compared to manual processes
- Ability to handle 3-5x more volume without hiring
- Consistent quality (AI never has bad days)
- 24/7 operation (email processing, data analysis, code review runs overnight)
- Competitive moat (competitors still using manual processes get disrupted)

---

## âš¡ Your First Gemini CLI Command in 60 Seconds

### Quickest Setup

**Step 1: Verify Gemini Access**
```bash
# Check if Gemini CLI is available on your system
which gemini
# If not installed, install via gcloud SDK
gcloud components install gemini-cli
```

**Step 2: Run Your First Command**
```bash
# Simple analysis - no files needed
gemini "What is the primary advantage of CI/CD automation in software development?"

# Expected: Instant answer with concrete explanation
```

**Step 3: Analyze a File**
```bash
# Read a local file and get AI analysis
gemini "Review this code for security issues and performance problems" < myapp.py

# Expected: Detailed analysis highlighting specific lines and recommendations
```

**Step 4: Pipe Data from Commands**
```bash
# Real-time data analysis
curl https://api.example.com/metrics | gemini "Identify any anomalies in this JSON data"

# Expected: Anomaly detection with explanation and recommendations
```

**What You'll Get**: Instant AI analysis from your terminal without switching applications. Analysis appears inline, can be piped to other commands or saved to files.

**Success Indicator**: Completed code review or data analysis entirely from command line in under 1 minute, without opening any web interfaces.

---

## ðŸŽ“ Progressive Mastery: 3 Skill Levels

### Level 1: Foundation (5 minutes)
*Master CLI basics and piped input for common development tasks*

**Scenario**: Your workflow involves frequent small analyses:
- Code review comments while reading diffs
- Quick documentation questions
- Understanding unfamiliar code
- API response analysis

Currently, you switch to web interface 10-15 times daily. You want instant terminal-based analysis.

**Mission**: Learn Gemini CLI for zero-context-switch development workflow.

#### Exercise 1.1: Basic File Analysis

**Setup**:
```bash
# Create a sample Python file to analyze
cat > example.py << 'EOF'
def calculate_total(prices):
    total = 0
    for price in prices:
        total = total + price
    return total

result = calculate_total([10, 20, 30])
print("Result: " + result)
EOF
```

**Task**: Review this code using Gemini CLI
```bash
gemini "Review this Python code for:
1. Bugs
2. Performance improvements
3. Pythonic patterns" < example.py
```

**Expected Output**:
```
CODE REVIEW RESULTS:

Bugs Found:
- Line 11: Type error - concatenating string with int. Should be: print(f"Result: {result}")

Performance:
- Line 5: Use sum() built-in instead of manual loop
- Recommended: return sum(prices)

Pythonic Patterns:
- Use sum(prices) instead of manual accumulation
- Consider type hints: def calculate_total(prices: list[float]) -> float:

Refactored Version:
def calculate_total(prices: list[float]) -> float:
    return sum(prices)
```

**What You Learned**:
- How to pipe file contents to Gemini
- Structured analysis from terminal
- Direct, actionable recommendations

#### Exercise 1.2: Git Diff Analysis

**Scenario**: You've made code changes and want instant feedback before committing.

**Task**: Analyze your uncommitted changes
```bash
# Get your current uncommitted changes
git diff > /tmp/my_changes.diff

# Send to Gemini for analysis
gemini "Review these code changes. Flag:
1. Any breaking changes
2. Potential bugs
3. Missing tests
4. Performance impacts" < /tmp/my_changes.diff
```

**Success Indicator**:
- Identified potential issues before committing
- Understood impact of changes
- Received specific recommendations

#### Exercise 1.3: Piped Command Analysis

**Task**: Analyze output from other commands without saving files

```bash
# Scenario 1: Analyze git log
git log --oneline -20 | gemini "What was this project's development focus over the last 20 commits?"

# Scenario 2: Analyze API response
curl https://jsonplaceholder.typicode.com/users/1 | gemini "What can you tell me about this user's data structure?"

# Scenario 3: Analyze system metrics
ps aux | gemini "Which processes are consuming the most resources? Any concerns?"

# Scenario 4: Analyze log files
tail -100 /var/log/application.log | gemini "Any error patterns? What needs attention?"
```

**What You Learned**:
- Piping command output directly to Gemini
- Real-time analysis without intermediate files
- Combining Unix commands with AI analysis

---

### Level 2: Intermediate (7 minutes)
*Build automated workflows using Git hooks and CI/CD integration*

**Scenario**: Your team commits code 20-30 times daily. Each commit should ideally be:
- Reviewed for basic quality issues
- Checked for security problems
- Verified for test coverage
- Analyzed for best practices

Currently: Manual, inconsistent, slow.
Goal: Automatic, consistent, instant feedback on every commit.

**Mission**: Build Git pre-commit hook that automatically analyzes code changes before allowing commit.

#### Exercise 2.1: Create Pre-Commit Hook

**Setup**:
```bash
# Navigate to your git repository
cd /path/to/your/repo

# Create hooks directory if needed
mkdir -p .git/hooks

# Create pre-commit hook file
cat > .git/hooks/pre-commit << 'EOF'
#!/bin/bash
set -e

# Get staged changes
CHANGES=$(git diff --cached)

# Analyze with Gemini
ANALYSIS=$(echo "$CHANGES" | gemini "Analyze these code changes.
Focus on:
1. CRITICAL ISSUES (security, crashes, data loss)
2. QUALITY ISSUES (style, performance, maintainability)
3. MISSING TESTS (areas needing test coverage)

Format: List issues by severity.
If no critical issues, start with: READY TO COMMIT")

# If critical issues found, prevent commit
if ! echo "$ANALYSIS" | grep -q "READY TO COMMIT"; then
    echo ""
    echo "âš ï¸  PRE-COMMIT ANALYSIS:"
    echo "$ANALYSIS"
    echo ""
    echo "Fix issues above before committing"
    exit 1
fi

echo "âœ… Code analysis: Passed"
exit 0
EOF

# Make executable
chmod +x .git/hooks/pre-commit
```

**How It Works**:
1. When you run `git commit`, the pre-commit hook runs automatically
2. Hook gets your staged changes
3. Sends to Gemini for analysis
4. If critical issues found, commit is blocked with error message
5. You fix issues and try again
6. If no critical issues, commit proceeds

**Test It**:
```bash
# Make a code change
echo "def broken(): return x" >> test.py

# Stage it
git add test.py

# Try to commit
git commit -m "test"

# Expected: Pre-commit hook blocks with analysis showing undefined variable 'x'
```

#### Exercise 2.2: Automated Code Review for Pull Requests

**Setup**: Create a script that analyzes PR diffs

```bash
# Create script
cat > scripts/analyze_pr.sh << 'EOF'
#!/bin/bash
# Usage: ./scripts/analyze_pr.sh origin/main

BASE_BRANCH=${1:-origin/main}

# Get diff between base and current branch
PR_DIFF=$(git diff "$BASE_BRANCH"...HEAD)

# Analyze with Gemini
ANALYSIS=$(echo "$PR_DIFF" | gemini "This is a code review for a pull request.
Analyze and provide:

1. SUMMARY: One-sentence description of changes

2. CRITICAL ISSUES (must fix before merge):
   - Security vulnerabilities
   - Breaking changes
   - Data loss risks
   - Crashes

3. IMPORTANT ISSUES (should fix):
   - Performance problems
   - Missing error handling
   - Code duplication

4. QUALITY SUGGESTIONS (nice to have):
   - Readability improvements
   - Pythonic/idiomatic patterns
   - Documentation needs

5. TEST COVERAGE:
   - Are tests included for changes?
   - Missing test scenarios?

6. REVIEWER CHECKLIST:
   - Can this be merged as-is?
   - Recommended changes?
   - Approval recommendation?")

# Save and display
echo "$ANALYSIS" | tee /tmp/pr_review.md

# Count critical issues
CRITICAL_COUNT=$(echo "$ANALYSIS" | grep -c "CRITICAL" || true)

if [ "$CRITICAL_COUNT" -gt 0 ]; then
    echo ""
    echo "âš ï¸  $CRITICAL_COUNT critical issues found. Address before merging."
    exit 1
else
    echo ""
    echo "âœ… PR analysis complete. Ready for human review."
    exit 0
fi
EOF

chmod +x scripts/analyze_pr.sh
```

**Usage**:
```bash
# Analyze PR against main branch
./scripts/analyze_pr.sh origin/main

# Or against specific commit
./scripts/analyze_pr.sh origin/main...HEAD
```

#### Exercise 2.3: Auto-Generate Tests

**Task**: Automatically generate unit tests for new code

```bash
# Create script
cat > scripts/generate_tests.sh << 'EOF'
#!/bin/bash
# Usage: ./scripts/generate_tests.sh myfile.py

CODE_FILE=$1
TEST_FILE="${CODE_FILE%.py}_test.py"

# Generate tests with Gemini
TESTS=$(gemini "Generate comprehensive unit tests for this Python code.

Requirements:
1. Use pytest framework
2. Aim for 80%+ coverage
3. Test happy path and error cases
4. Include fixtures for test data
5. Use descriptive test names
6. Add docstrings explaining what's tested

Code to test:
$(cat $CODE_FILE)

Output: Only the test code (ready to run with pytest)" < "$CODE_FILE")

# Save to file
echo "$TESTS" > "$TEST_FILE"

echo "âœ… Tests generated: $TEST_FILE"
echo "Run with: pytest $TEST_FILE -v"
EOF

chmod +x scripts/generate_tests.sh
```

**Usage**:
```bash
# Generate tests for your code
./scripts/generate_tests.sh myapp.py

# Run the generated tests
pytest myapp_test.py -v
```

#### Exercise 2.4: CI/CD Pipeline Integration

**Add to your CI/CD** (GitHub Actions example):

```yaml
# .github/workflows/ai-code-review.yml
name: AI Code Review
on:
  pull_request:
    paths:
      - '**.py'
      - '**.js'
      - '**.ts'

jobs:
  analyze:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Full history for diff analysis

      - name: Set up Gemini
        run: |
          # Configure Gemini access
          echo "$GEMINI_API_KEY" > ~/.gemini_token

      - name: Analyze PR with Gemini
        run: |
          # Get PR diff
          git diff origin/${{ github.base_ref }} > /tmp/pr.diff

          # Run analysis
          gemini "Review this pull request diff for:
          1. Security issues
          2. Performance problems
          3. Code quality issues
          4. Test coverage gaps
          5. Breaking changes

          Provide specific line numbers and recommendations." < /tmp/pr.diff > /tmp/review.md

          # Post as comment
          cat /tmp/review.md

      - name: Generate Test Summary
        run: |
          git diff origin/${{ github.base_ref }} | gemini "Identify what areas of code changed. Suggest unit tests that should be added." > /tmp/test_suggestions.md

      - name: Fail if critical issues
        run: |
          if grep -q "CRITICAL" /tmp/review.md; then
            echo "Critical issues found in code review"
            exit 1
          fi
```

---

### Level 3: Advanced (8 minutes)
*Build end-to-end automation: email processing, daily reports, monitoring alerts*

**Scenario**: Support team receives 100+ emails daily. Process:
- Email arrives
- Categorize issue (bug/feature/account/billing/other)
- Assess severity (critical/high/medium/low)
- Generate response (if straightforward) or escalate
- Log and assign to team
- Follow up if needed

Currently: Manual â†’ 8-10 minutes per email â†’ ~100-150 hours/month

Goal: Automated â†’ 1-2 minutes per email â†’ ~10-20 hours/month

**Mission**: Build complete end-to-end automation workflow.

#### Exercise 3.1: Email Triage and Response

```bash
# Create script: scripts/process_support_email.sh
cat > scripts/process_support_email.sh << 'EOF'
#!/bin/bash
# Process support email automatically
# Usage: ./process_support_email.sh email.txt

EMAIL_FILE=$1
EMAIL_CONTENT=$(cat "$EMAIL_FILE")

# Step 1: Extract and categorize
echo "Analyzing email..."
ANALYSIS=$(gemini "Extract from this support email:

1. SENDER: Customer name and email
2. ISSUE TYPE: bug / feature request / account / billing / other
3. SEVERITY: critical (down/broken) / high (major impact) / medium / low
4. PROBLEM SUMMARY: 2-3 sentence description
5. CUSTOMER REQUEST: What do they want us to do?
6. RELATED SYSTEMS: Which products/systems affected?

Format output as: Key:Value pairs for easy parsing

Email:
$EMAIL_CONTENT")

# Parse analysis
ISSUE_TYPE=$(echo "$ANALYSIS" | grep "ISSUE TYPE:" | cut -d':' -f2 | xargs)
SEVERITY=$(echo "$ANALYSIS" | grep "SEVERITY:" | cut -d':' -f2 | xargs)
SENDER=$(echo "$ANALYSIS" | grep "SENDER:" | cut -d':' -f2 | xargs)

echo "  Type: $ISSUE_TYPE | Severity: $SEVERITY | Sender: $SENDER"

# Step 2: Generate response
echo "Generating response..."
RESPONSE=$(gemini "Draft professional support response to this customer email.

Context:
- Issue type: $ISSUE_TYPE
- Severity: $SEVERITY

The response should:
1. Thank them for reporting the issue
2. Show understanding of their problem
3. Provide solution (if available) OR explain next steps
4. Set expectations for timeline
5. Provide escalation path if needed
6. Professional but friendly tone
7. 150-250 words

Email to respond to:
$EMAIL_CONTENT

Output: Just the response text")

# Step 3: Route and assign
case "$ISSUE_TYPE" in
  "bug")
    OWNER="engineering"
    PRIORITY=$SEVERITY
    ;;
  "feature")
    OWNER="product"
    PRIORITY="medium"
    ;;
  "billing"|"account")
    OWNER="support"
    PRIORITY=$SEVERITY
    ;;
  *)
    OWNER="general"
    PRIORITY="low"
    ;;
esac

# Step 4: Save to system
LOG_DIR="support_logs/$(date +%Y%m%d)"
mkdir -p "$LOG_DIR"
LOG_FILE="$LOG_DIR/${SENDER// /_}_$(date +%s).txt"

cat > "$LOG_FILE" << LOGEOF
TIMESTAMP: $(date)
SENDER: $SENDER
TYPE: $ISSUE_TYPE
SEVERITY: $SEVERITY
OWNER: $OWNER
PRIORITY: $PRIORITY

ANALYSIS:
$ANALYSIS

SUGGESTED RESPONSE:
$RESPONSE

---
Status: Queued for ${OWNER} team
LOGEOF

# Step 5: Queue or send
if [ "$SEVERITY" = "critical" ]; then
    # Critical issues need human review before sending
    echo "âš ï¸  CRITICAL: Queued for immediate $OWNER review"
    echo "$RESPONSE" | mail -s "URGENT: $ISSUE_TYPE - Review Response" ${OWNER}@company.com
else
    # Non-critical can auto-send
    echo "âœ… Response queued to $SENDER"
    # In production, would actually send email here
fi
EOF

chmod +x scripts/process_support_email.sh
```

#### Exercise 3.2: Daily Support Summary

```bash
# Create script: scripts/daily_support_summary.sh
cat > scripts/daily_support_summary.sh << 'EOF'
#!/bin/bash
# Generate daily support summary

SUPPORT_LOG_DIR="support_logs/$(date +%Y%m%d)"

# Gather all emails from today
SUMMARY_INPUT=""
if [ -d "$SUPPORT_LOG_DIR" ]; then
    SUMMARY_INPUT=$(cat "$SUPPORT_LOG_DIR"/*.txt)
else
    echo "No support logs found for today"
    exit 0
fi

# Generate comprehensive summary
SUMMARY=$(gemini "Analyze today's support emails and provide:

1. VOLUME & BREAKDOWN:
   - Total emails: count
   - By type: bug/feature/account/billing/other
   - By severity: critical/high/medium/low

2. MOST COMMON ISSUES:
   - Top 3-5 issues reported
   - How many customers affected
   - Is this a pattern or anomaly?

3. CRITICAL ALERTS:
   - Any critical issues needing immediate action?
   - Products/systems most affected?
   - Customer impact assessment?

4. TEAM WORKLOAD:
   - Expected workload by team
   - Recommendations for resource allocation
   - Are we understaffed for today's volume?

5. TRENDS & INSIGHTS:
   - New issue types appearing?
   - Customer sentiment changes?
   - Recommendations for improvement?

6. FOLLOW-UP ACTIONS:
   - What should the team prioritize today?
   - Any product/engineering recommendations?
   - Process improvements needed?

Support Data:
$SUMMARY_INPUT")

# Save and distribute
REPORT_FILE="reports/support_summary_$(date +%Y%m%d).md"
mkdir -p reports
echo "# Daily Support Summary - $(date +%Y-%m-%d)" > "$REPORT_FILE"
echo "$SUMMARY" >> "$REPORT_FILE"

# Email to team
echo "ðŸ“Š Daily Support Summary" > /tmp/email.txt
echo "Sent: $(date)" >> /tmp/email.txt
echo "" >> /tmp/email.txt
echo "$SUMMARY" >> /tmp/email.txt

mail -s "Daily Support Summary: $(date +%Y-%m-%d)" support-team@company.com < /tmp/email.txt

echo "âœ… Daily summary generated and sent"
EOF

chmod +x scripts/daily_support_summary.sh

# Schedule as cron job
# Add to crontab: 0 17 * * * /path/to/scripts/daily_support_summary.sh
```

#### Exercise 3.3: Real-Time Monitoring & Alerts

```bash
# Create script: scripts/monitor_and_alert.sh
cat > scripts/monitor_and_alert.sh << 'EOF'
#!/bin/bash
# Monitor system/application and alert on issues

ALERT_FILE="/tmp/gemini_alerts_$(date +%Y%m%d).txt"
touch "$ALERT_FILE"

# Monitoring loop (runs every 5 minutes)
while true; do
    # Gather current metrics
    echo "Checking metrics at $(date)..."

    # Option 1: Application logs
    RECENT_LOGS=$(tail -50 /var/log/application.log)

    # Option 2: API health
    API_STATUS=$(curl -s https://api.example.com/health || echo "DOWN")

    # Option 3: Database metrics
    DB_METRICS=$(mysql -e "SHOW STATUS LIKE '%Threads%';" 2>/dev/null || echo "N/A")

    # Combine and analyze
    CURRENT_STATE="
    Timestamp: $(date)
    API Status: $API_STATUS
    Recent Logs: $RECENT_LOGS
    DB Status: $DB_METRICS
    "

    # Analyze with Gemini
    ANALYSIS=$(gemini "Monitor alert system. Check for:
    1. Errors or exceptions in logs
    2. Service outages or slowdowns
    3. Database issues or high load
    4. Unusual patterns or anomalies
    5. Security concerns

    If issues found, provide:
    - Issue description
    - Severity (critical/high/medium/low)
    - Recommended action
    - Who to alert

    Current state:
    $CURRENT_STATE")

    # Check if alerts needed
    if echo "$ANALYSIS" | grep -q -E "critical|error|DOWN|anomaly"; then
        # Alert found - log and notify
        echo "$ANALYSIS" >> "$ALERT_FILE"

        # Send email alert
        SEVERITY=$(echo "$ANALYSIS" | grep -i severity | head -1)
        echo "ðŸš¨ ALERT: $SEVERITY" | mail -s "System Alert: $(date)" ops@company.com

        # Optional: Page on-call engineer for critical
        if echo "$SEVERITY" | grep -q "critical"; then
            # Call pagerduty API or similar
            :
        fi
    fi

    # Check every 5 minutes
    sleep 300
done
EOF

chmod +x scripts/monitor_and_alert.sh
```

---

## ðŸš€ Production Templates: Ready-to-Use Automation

### Template 1: Pre-Commit Code Analysis Hook

```bash
#!/bin/bash
# Place in: .git/hooks/pre-commit
# Automatically analyzes code before allowing commit

set -e

CHANGES=$(git diff --cached)

ANALYSIS=$(gemini "Review these staged code changes.
Identify and report:

CRITICAL ISSUES (prevent commit):
- Syntax errors
- Security vulnerabilities
- Data loss risks
- Breaking changes

QUALITY ISSUES (warning):
- Performance problems
- Code duplication
- Missing error handling
- Poor variable names

If critical issues: Start response with [CRITICAL]
If no critical issues: Start with [OK_TO_COMMIT]" << EOF
$CHANGES
EOF
)

if echo "$ANALYSIS" | grep -q "\[CRITICAL\]"; then
    echo ""
    echo "âŒ CRITICAL ISSUES FOUND:"
    echo "$ANALYSIS"
    echo ""
    echo "Fix issues above and try again"
    exit 1
fi

if echo "$ANALYSIS" | grep -q "\[OK_TO_COMMIT\]"; then
    echo "âœ… Code analysis: Passed"
fi

exit 0
```

**Use When**:
- Team has quality issues in commits
- Want consistency without code review overhead
- Need to prevent certain types of errors

**Time Saved**:
- 2-3 hours/week (prevents bad commits, reduces review time)
- Improves code quality baseline

---

### Template 2: Email Auto-Triage

```bash
#!/bin/bash
# Automatically triage incoming support emails

EMAIL=$1

TRIAGE=$(gemini "Triage this support email.
Extract:
1. Issue type: bug/feature/account/billing/other
2. Severity: critical/high/medium/low
3. Category: [specific area]
4. Suggested response draft

Format as: TYPE|SEVERITY|CATEGORY|[Draft response]

Email:
$(cat $EMAIL)")

# Parse and route
IFS='|' read -r TYPE SEVERITY CATEGORY RESPONSE <<< "$TRIAGE"

# Route to team based on type
case "$TYPE" in
  bug) TEAM="engineering" ;;
  feature) TEAM="product" ;;
  *) TEAM="general" ;;
esac

# Log
echo "$TRIAGE" >> "logs/triaged_$(date +%Y%m%d).txt"

# Queue for human review or auto-send based on severity
if [ "$SEVERITY" = "critical" ]; then
    echo "CRITICAL: Queued for immediate review"
else
    echo "$RESPONSE" | mail -s "Support: $CATEGORY" "$TEAM@company.com"
fi
```

**Use When**:
- Support team drowning in email volume
- Need fast categorization and routing
- Want to standardize response quality

**Time Saved**:
- 5-10 hours/day (email processing)
- Monthly: 120-240 hours

---

### Template 3: Daily Performance Report

```bash
#!/bin/bash
# Generate daily performance report

REPORT=$(gemini "Analyze performance metrics and logs.
Provide executive summary with:

1. Key metrics (uptime, latency, throughput)
2. Issues or anomalies detected
3. Performance trends
4. Recommendations

Data:
$(cat /var/log/metrics.log)")

echo "# Performance Report: $(date +%Y-%m-%d)" > report.md
echo "$REPORT" >> report.md

# Email to team
mail -s "Daily Performance Report" team@company.com < report.md
```

**Use When**:
- Need consistent daily reporting
- Want automated anomaly detection
- Want insights without manual analysis

**Time Saved**:
- 30 minutes/day (manual report generation)

---

### Template 4: Content Processing Pipeline

```bash
#!/bin/bash
# Auto-process articles/content

ARTICLE=$1

# Get article
CONTENT=$(cat "$ARTICLE")

# Process in parallel
gemini "Summarize this article in 1-2 paragraphs" <<< "$CONTENT" > summary.txt &
gemini "Extract 5 key takeaways" <<< "$CONTENT" > takeaways.txt &
gemini "Generate social media snippets (Twitter, LinkedIn, Instagram)" <<< "$CONTENT" > social.txt &
gemini "Create list of 10 relevant hashtags" <<< "$CONTENT" > hashtags.txt &

wait

# Combine outputs
echo "Article: $ARTICLE" > processed.md
echo "" >> processed.md
echo "## Summary" >> processed.md
cat summary.txt >> processed.md
echo "" >> processed.md
echo "## Key Takeaways" >> processed.md
cat takeaways.txt >> processed.md
echo "" >> processed.md
echo "## Social Media" >> processed.md
cat social.txt >> processed.md

echo "âœ… Content processed: processed.md"
```

**Use When**:
- Publishing frequently
- Need consistent content formatting
- Want to maximize content reach

**Time Saved**:
- 45 minutes per article

---

### Template 5: Real-Time Data Monitoring

```bash
#!/bin/bash
# Monitor data feeds for anomalies

check_data() {
    DATA=$(curl -s $1)

    ALERT=$(echo "$DATA" | gemini "Check for anomalies in this data.
    If problems found, format as:
    [ALERT] Issue description
    [ACTION] Recommended action

    Otherwise output [OK]")

    if echo "$ALERT" | grep -q "\[ALERT\]"; then
        echo "$ALERT"
        # Send alert
        mail -s "Data Anomaly Alert" ops@company.com <<< "$ALERT"
    fi
}

# Monitor multiple feeds
while true; do
    check_data "https://api.example.com/feed1"
    check_data "https://api.example.com/feed2"
    check_data "https://api.example.com/feed3"
    sleep 300  # Check every 5 minutes
done
```

**Use When**:
- Need real-time monitoring
- Want automated alerting
- Difficult to write rules for anomalies

**Time Saved**:
- 24/7 monitoring without manual work

---

## ðŸ’¼ Business Integration & 90-Day Transformation

### This Week: Foundation

**Monday: Setup & First Automation** (2 hours)
- [ ] Install Gemini CLI and verify access
- [ ] Read this lesson completely
- [ ] Create first automation (pick one template)
- [ ] Test with real data

**Tuesday: Git Integration** (2 hours)
- [ ] Create pre-commit hook
- [ ] Test on 5 actual commits
- [ ] Refine rules based on output
- [ ] Share with team

**Wednesday: Process Analysis** (1 hour)
- [ ] Identify what takes most team time
- [ ] Map to automation opportunity
- [ ] Draft second automation script

**Thursday: Testing & Documentation** (1.5 hours)
- [ ] Test second automation thoroughly
- [ ] Document setup process
- [ ] Create runbook for team

**Friday: Review & Planning** (1 hour)
- [ ] Review week's results
- [ ] Calculate time saved
- [ ] Plan next automations
- [ ] Share wins with team

**Week 1 Results**:
- 1-2 automations deployed
- 10-20 hours saved (multiplied across team)
- Team aware of possibilities
- Foundation for expansion

---

### This Month: Scaling

**Week 2: Build Automation Suite** (8 hours)
- Email triage automation
- Code review automation
- Daily report generation
- Add 2-3 more based on team needs

**Week 3: Integration & Testing** (6 hours)
- Integrate with CI/CD pipelines
- Set up scheduled jobs
- Create monitoring for automations
- Troubleshoot issues

**Week 4: Optimization & Training** (6 hours)
- Refine based on first month data
- Train full team
- Gather feedback
- Plan next phase

**Month 1 Results**:
- 5-10 automations deployed
- 60-100 hours/month saved (team-wide)
- Reduced manual work significantly
- Foundation for enterprise automation

---

### 90-Day Transformation

**Month 2: Enterprise Automation** (20 hours)
- Build 5-10 more automations
- Integrate into all departments
- Create central automation hub
- Establish automation guidelines

**Month 3: Optimization & Strategy** (15 hours)
- Optimize based on 2 months data
- Plan next generation automations
- Build custom solutions
- Establish center of excellence

**90-Day Results**:
```
TOTAL AUTOMATION DEPLOYED: 15-20
MONTHLY TIME SAVED: 300-500 hours
ANNUAL VALUE: $360K-600K+
TEAM SATISFACTION: +40-50%
PROCESS EFFICIENCY: +150-200%

PER TEAM MEMBER:
Weekly time freed: 6-10 hours
Automated tasks: 50-100% of routine work
Quality improvement: +30-40%
Job satisfaction: Higher (less busywork)
```

---

## ðŸ”§ Troubleshooting & Pro Tips

### Common Problems & Solutions

**Problem 1: "CLI command is slow; waiting 5-10 seconds per request"**

Solution:
```bash
# Use batch processing instead of one-at-a-time
# Combine multiple analyses in single request
gemini "Analyze all 10 of these code files:
File 1: [code]
File 2: [code]
...
File 10: [code]

For each: identify issues, suggest improvements"

# Result: 10 files analyzed in one request instead of 10 requests
```

**When to use**: Processing multiple items (emails, files, logs)
**Time saved**: 50% (10 requests â†’ 1 request)

---

**Problem 2: "Automation generating too many false positives - alerts when unnecessary"**

Solution:
```bash
# Add confidence thresholds and filters
ANALYSIS=$(gemini "Analyze this with high confidence threshold.
Only report issues you're very certain about.
Skip minor style issues.
Focus on: bugs, performance, security.

Confidence level for each finding: HIGH/MEDIUM/LOW
Only output HIGH confidence findings.")

# Filter further if needed
if echo "$ANALYSIS" | grep -c "HIGH" > 5; then
    # Too many issues - likely false positives
    echo "Review manually"
else
    # Safe to action
fi
```

**When to use**: Production automation where false alerts are costly
**Impact**: 70% reduction in false positives

---

**Problem 3: "Integration with existing tools is complex"**

Solution:
```bash
# Use webhooks and event routing
# Example: GitHub webhook â†’ Gemini analysis â†’ Slack notification

# Setup webhook handler
cat > server.py << 'EOF'
from flask import Flask, request
import subprocess
import json

app = Flask(__name__)

@app.route('/github-webhook', methods=['POST'])
def github_webhook():
    data = request.json

    # Extract PR diff
    diff_url = data['pull_request']['diff_url']
    diff = requests.get(diff_url).text

    # Analyze
    result = subprocess.run(
        ['gemini', 'Analyze this PR diff'],
        input=diff,
        capture_output=True,
        text=True
    )

    # Post to Slack
    slack_post(result.stdout)

    return 'OK'
EOF
```

**When to use**: Integrating with platforms (GitHub, GitLab, Jira, Slack)
**Impact**: Seamless workflow integration

---

**Problem 4: "How do I prevent sensitive data from being sent to Gemini?"**

Solution:
```bash
# Filter sensitive data before sending
SANITIZE=$(echo "$DATA" | sed -E '
  s/[0-9]{4}-[0-9]{4}-[0-9]{4}-[0-9]{4}/CREDIT_CARD/g
  s/[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/EMAIL/g
  s/api[_-]?key[=:]\s*[^\s]*/API_KEY/g
  s/password[=:]\s*[^\s]*/PASSWORD/g
')

# Analyze sanitized version
gemini "Analyze this data" <<< "$SANITIZE"
```

**When to use**: Processing customer data, PII, credentials
**Impact**: Maintains privacy compliance

---

**Problem 5: "Gemini API costs are getting high"**

Solution:
```bash
# Batch similar requests
# Instead of: 100 small requests
# Do: 1 large request with 100 items

# Combine data
COMBINED="Analyze these 100 support emails:
Email 1: [content]
Email 2: [content]
...
Email 100: [content]"

# Process once
gemini "Categorize each email and provide summary" <<< "$COMBINED"

# Cost reduction: 100 API calls â†’ 1 API call = 99% savings
```

**When to use**: High-volume processing
**Impact**: 90%+ cost reduction for batch operations

---

### Pro Tips from Experts

**ðŸ’¡ Technique 1: Structured Output for Parsing**

Always instruct Gemini to output in machine-readable format:

```bash
ANALYSIS=$(gemini "Analyze code.
Output format:
ISSUE_COUNT: [number]
SEVERITY: [critical/high/medium/low]
ISSUES:
- [issue 1]
- [issue 2]
" < code.py)

# Now you can parse reliably
ISSUE_COUNT=$(echo "$ANALYSIS" | grep "ISSUE_COUNT:" | cut -d':' -f2)
SEVERITY=$(echo "$ANALYSIS" | grep "SEVERITY:" | cut -d':' -f2)

# Use in conditionals
if [ "$SEVERITY" = "critical" ]; then
    # Do something
fi
```

**Impact**: 100% reliable automation (vs. 70% with free-form output)

---

**ðŸ’¡ Technique 2: Confidence Scoring**

Ask Gemini to rate its confidence:

```bash
ANALYSIS=$(gemini "Identify bugs in this code.
For each finding, rate:
CONFIDENCE: 90-100% (definitely a bug) / 70-89% (likely) / <70% (unsure)

Only report 90%+ confidence findings." < code.py)

# Process only high-confidence results
if grep -q "CONFIDENCE: 9[0-9]" <<< "$ANALYSIS"; then
    # Safe to automate action
fi
```

**Impact**: Reduces false positives to <5%

---

**ðŸ’¡ Technique 3: Progressive Validation**

Multi-stage automation with human checkpoints:

```bash
# Stage 1: Auto-analyze and categorize
CATEGORY=$(gemini "Categorize this" <<< "$INPUT" | grep -o "^[A-Z]*")

# Stage 2: Auto-response for simple cases
if [ "$CATEGORY" = "FAQ" ]; then
    # Auto-answer
    RESPONSE=$(gemini "Generate response" <<< "$INPUT")
else
    # Queue for human review
    echo "$INPUT" >> queue_for_review.txt
    exit 0
fi

# Stage 3: Send if low risk, review if high risk
if [ "$RISK" = "low" ]; then
    send_response "$RESPONSE"
else
    notify_human "Review: $RESPONSE"
fi
```

**Impact**: 80% automation + human oversight for complex cases

---

**ðŸ’¡ Technique 4: Parallel Processing**

Speed up workflows with parallel Gemini calls:

```bash
# Process 5 files in parallel
for file in file1 file2 file3 file4 file5; do
    gemini "Analyze this" < "$file" > "${file}.analysis" &
done
wait  # Wait for all to complete

# Combine results
cat *.analysis > combined_analysis.txt
```

**Impact**: 5x faster than sequential processing

---

**ðŸ’¡ Technique 5: Context Compression**

For large workflows, summarize context to save tokens:

```bash
# Instead of: sending full 1000-line file
# Do: Send summary

SUMMARY=$(gemini "Summarize this code focusing on:
- What it does
- Key functions
- Any obvious issues" < large_file.py)

# Use summary for subsequent analysis
gemini "Based on this code summary, suggest improvements:
$SUMMARY"

# Token usage: 60% reduction
```

**Impact**: 40-60% cost savings on large documents

---

## ðŸŽ¯ Your 90-Day Action Plan

### Week 1: Foundation (7 hours)

**Day 1: Setup (1 hour)**
- [ ] Install Gemini CLI
- [ ] Test with 5 simple commands
- [ ] Read templates section

**Day 2: First Automation (2 hours)**
- [ ] Choose one template
- [ ] Customize for your use case
- [ ] Create script file
- [ ] Test with real data

**Day 3: Git Integration (2 hours)**
- [ ] Create pre-commit hook
- [ ] Test on 5 actual commits
- [ ] Measure time improvement

**Day 4-5: Refinement (2 hours)**
- [ ] Refine automation based on results
- [ ] Fix false positives
- [ ] Document process

**Week 1 Metric**: 1 automation deployed, 10+ hours saved

---

### Month 1: Scaling (20 hours)

**Week 2: Build Suite**
- Deploy 3-5 more automations
- Integrate with team workflows
- Track time/cost savings

**Week 3: Production Ready**
- Add error handling
- Create monitoring
- Set up alerts
- Document runbooks

**Week 4: Optimization**
- Analyze data from 3 weeks
- Optimize high-value automations
- Train team
- Plan next phase

**Month 1 Metric**: 5-10 automations, 100+ hours/month saved, $10K-15K value

---

### Months 2-3: Enterprise (35 hours)

**Month 2: Expand Across Teams**
- Deploy automations to other departments
- Build integration hub
- Establish automation standards
- Create reusable templates

**Month 3: Advanced Automations**
- Multi-stage workflows
- Cross-system integration
- Advanced monitoring
- Custom solutions

**90-Day Metric**: 15-20 automations, 300-500 hours/month saved, $360K-600K annual value

---

**Next Lesson**: Lesson 28 - Comparing All Three Platforms ðŸš€
